# Amazon Product Scraper (Python + Selenium)

## üìå Project Overview

This project is a **Python-based web scraping automation tool** that extracts detailed product information from **Amazon India** based on a user‚Äôs search query. The scraper automatically navigates through search result pages, opens individual product pages, collects structured product data, and exports the results into an **Excel file** for further analysis.

This project is built mainly for **learning, practice purposes**.

---

## üéØ Objectives

* Automate product search on Amazon
* Handle **dynamic content** using Selenium
* Extract detailed product-level information
* Store data in a clean, structured format
* Export final data to **Excel (.xlsx)** using Pandas

---

## üõ†Ô∏è Technologies & Libraries Used

* **Python 3** ‚Äì Core programming language
* **Selenium** ‚Äì Browser automation & dynamic content handling
* **Chrome WebDriver** ‚Äì Automates Google Chrome
* **Pandas** ‚Äì Data storage and Excel export
* **BeautifulSoup (bs4)** ‚Äì HTML parsing (optional / future use)
* **OS & Time modules** ‚Äì File handling and delays

---

## ‚öôÔ∏è Features

* Headless browser execution (runs without UI)
* Automated scrolling to load lazy-loaded content
* Multi-page navigation (Next page handling)
* Safe element extraction with error handling
* Extracts both **text data** and **tabular specifications**
* Stores output in Excel format
* Configurable product search via user input

---

## üìÇ Data Extracted

For each product, the scraper collects:

* Product Title
* Price & Actual Price
* Discount / Savings Percentage
* Review Count
* Star Ratings
* Store / Brand Name
* Offers & Promotional Messages
* Product Variants
* Bullet-point Descriptions
* Technical Specifications (tables)

---

## üîÑ Workflow Explanation

1. User enters a **search keyword** (e.g., mobile phones)
2. Script opens Amazon India in headless Chrome
3. Product search is performed automatically
4. All product URLs are collected from result pages
5. Each product page is opened individually
6. Product data is safely extracted
7. Data is stored in a list of dictionaries
8. Pandas converts data into a DataFrame
9. Final output is saved as an Excel file

---

## ‚ñ∂Ô∏è How to Run the Project

### 1Ô∏è‚É£ Prerequisites

* Python installed (3.8+ recommended)
* Google Chrome installed
* ChromeDriver matching your Chrome version

### 2Ô∏è‚É£ Install Required Libraries

```bash
pip install selenium pandas bs4 openpyxl
```

### 3Ô∏è‚É£ Update ChromeDriver Path

Update the following line in the script:

```python
path = "D:/Web Scraping/chromedriver-win64/chromedriver.exe"
```

### 4Ô∏è‚É£ Run the Script

```bash
python scraper.py
```

### 5Ô∏è‚É£ Output

An Excel file will be generated:

```
<search_text>_data.xlsx
```

---

## üß™ Error Handling & Stability

* Uses `try-except` blocks to avoid crashes
* Handles missing elements gracefully
* Uses delays (`time.sleep`) to prevent page load issues
* Stops scraping after a defined limit (100 products)

---

## ‚ö†Ô∏è Important Notes

* This project is intended for **educational purposes only**
* Web scraping should always respect **website terms & policies**
* Avoid excessive requests to prevent IP blocking




